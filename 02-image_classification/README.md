# ğŸ” Real-Time Image Classification

This project demonstrates **real-time image classification** using a **quantized MobileNetV1 classification model**  with **TensorFlow Lite** and **OpenCV** for **single-label image classification**.

Designed for cross-platform use (Linux, Windows, embedded boards like NXP i.MX8M Plus), it supports **hardware acceleration** via delegates like **NPU or GPU**.

---

![Demo GIF](output.gif)

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ main.py                         # Your main script (e.g., live camera inference)
â”œâ”€â”€ label_image.py                  # Image classification script for static images 
â”œâ”€â”€ labels.py                       # Label mapping (class index to name)  
â”œâ”€â”€ ssd_mobilenet_v1_quant.tflite   # Quantized TFLite model  
â”œâ”€â”€ README.md                       # This documentation
```

---

## ğŸ§  Model Information

- **Model**: MobileNetV1 classification model  (Quantized)  
- **Format**: TensorFlow Lite (`.tflite`)  

âœ… Optimized for edge devices  
ğŸ§  Compatible with NPU delegate (`libvx_delegate.so`) on platforms like i.MX8MP

---

## âœ… Dependencies

Install with:

```bash
pip install opencv-python tflite-runtime
```

### Requirements:
- Python 3.6+
- OpenCV â€“ for video stream processing and display
- TFLite Runtime â€“ for inference

### ğŸ” Note  
The `opencv-python` package automatically installs the latest version of **NumPy** that is compatible with your Python version.  
However, this program (or one of its dependencies) requires **NumPy version 1.x**, because modules compiled against NumPy 1.x may crash when used with NumPy 2.x or later.

To fix this issue, downgrade NumPy by running:  
```bash
pip install "numpy<2.0"
```
---

## ğŸš€ How to Run

### 1ï¸âƒ£ Run with CPU:

```bash
python main.py
```
### 2ï¸âƒ£ Run with NPU/GPU delegate:

```bash
python main.py -d path/to/libvx_delegate.so
```

> âœ… Ensure `libvx_delegate.so` exists on your device.

### 3ï¸âƒ£ Use a different camera or video file:

```bash
# Use camera index X
python main.py --camera_id X

# Use a video file
python main.py --camera_id path/to/video.mp4
```
---

## ğŸ“ Label Mapping (`labels.txt`)

This file maps class indices to human-readable labels:

```text
   background
   tench
   goldfish
   great white shark
   tiger shark
   # Add more as needed
```

> ğŸ” Ensure these labels correspond exactly to the classes your .tflite model was trained on, so that predictions map correctly to meaningful names.

---

## ğŸ¯ Output

- ğŸ·ï¸ Top predicted class labels with confidence scores
- â±ï¸ Inference time per frame (in milliseconds)
- ğŸ“¤ Console prints showing predicted labels and scores in real-time 

### ğŸ“Ÿ Console Output Example

```text
0.953214: golden retriever 
Inference: 23.45 ms
```

### ğŸ–¼ï¸ Display

- A window showing the video stream annotated with predicted class labels and their confidence scores
- Inference time displayed on the video frame
- Press **`q`** to quit.

---

## âš™ï¸ Internal Processing Flow

1. Initialize video source (camera or file)
2. Load TFLite classification model(with or without delegate)
3. Capture frame from video source
4. Preprocess frame (resize to 224Ã—224)
5. Run inference on the preprocessed frame
6. Postprocess output:
   - Extract top predicted classes and confidence scores 
   - Map class indices to labels
7. Display annotated frame with  predicted labels and inference time
8. Repeat until exit

---

## ğŸ’¡ Tips

- âœ… Use **quantized models (uint8)** for better hardware compatibility
- ğŸš€ For NXP i.MX8MP, use **`libvx_delegate.so`** to run on the NPU
- ğŸ“ Adjust input size/resolution to balance accuracy and performance
