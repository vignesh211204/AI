# ğŸ” Real-Time Object Detection

This project demonstrates **real-time object detection** using a **quantized MobileNet SSD model** with **TensorFlow Lite** and **OpenCV**.

Designed for cross-platform use (Linux, Windows, embedded boards like NXP i.MX8M Plus), it supports **hardware acceleration** via delegates like **NPU or GPU**.

---

![Demo GIF](output.gif)

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ detect.py                      # Main object detection script  
â”œâ”€â”€ labels.py                      # Label mapping (class index to name)  
â”œâ”€â”€ ssd_mobilenet_v1_quant.tflite  # Quantized TFLite model  
â”œâ”€â”€ README.md                      # This documentation
```

---

## ğŸ§  Model Information

- **Model**: SSD MobileNet V1 (Quantized)  
- **Format**: TensorFlow Lite (`.tflite`)  

âœ… Optimized for edge devices  
ğŸ§  Compatible with NPU delegate (`libvx_delegate.so`) on platforms like i.MX8MP

---

## âœ… Dependencies

Install with:

```bash
pip install opencv-python pillow tflite-runtime
```

### Requirements:
- Python 3.6+
- OpenCV â€“ for video stream processing
- Pillow â€“ for image handling
- TFLite Runtime â€“ for inference
  
### ğŸ” Note  
The `opencv-python` package automatically installs the latest version of **NumPy** that is compatible with your Python version.  
However, this program (or one of its dependencies) requires **NumPy version 1.x**, because modules compiled against NumPy 1.x may crash when used with NumPy 2.x or later.

To fix this issue, downgrade NumPy by running:  
```bash
pip install "numpy<2.0"
```
---

## ğŸš€ How to Run

### 1ï¸âƒ£ Run with CPU:

```bash
python main.py
```
### 2ï¸âƒ£ Run with NPU/GPU delegate:

```bash
python main.py -d path/to/libvx_delegate.so
```

> âœ… Ensure `libvx_delegate.so` exists on your device.

### 3ï¸âƒ£ Use a different camera or video file:

```bash
# Use camera index X
python main.py -i X

# Use a video file
python main.py -i path/to/video.mp4
```
---

## ğŸ“ Label Mapping (`labels.py`)

This file maps class indices to human-readable labels:

```python
label2string = {
    0: 'person',
    1: 'car',
    2: 'bicycle',
    3: 'motorcycle',
    4: 'airplane',
    5: 'bus',
    # Add more as needed
}
```

> ğŸ” Make sure these match the classes used in your `.tflite` model.

---

## ğŸ¯ Output

- ğŸŸ¥ Bounding boxes  
- ğŸ·ï¸ Class labels  
- ğŸ“ˆ FPS (frames per second)  
- â±ï¸ Inference time per frame  

### ğŸ“Ÿ Console Output Example

```text
Detection: (84, 130)-(210, 310) Label: person
FPS: 26  Inference: 15ms
```

### ğŸ–¼ï¸ Display

- A window shows the annotated video stream in real time.
- Press **`q`** to quit.

---

## âš™ï¸ Internal Processing Flow

1. Initialize video source (camera or file)
2. Load TFLite model (with or without delegate)
3. Preprocess frame (resize to 300Ã—300)
4. Run inference
5. Postprocess:
   - Parse output tensors
   - Draw bounding boxes
   - Map class indices to labels
6. Display frame with FPS and timing
7. Repeat until exit

---

## ğŸ’¡ Tips

- âœ… Use **quantized models (uint8)** for better hardware compatibility
- ğŸš€ For NXP i.MX8MP, use **`libvx_delegate.so`** to run on the NPU
- ğŸ“ Adjust input size/resolution to balance accuracy and performance
